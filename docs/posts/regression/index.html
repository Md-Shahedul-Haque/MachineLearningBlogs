<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Md Shahedul Haque">
<meta name="dcterms.date" content="2023-11-29">

<title>Machine Learning Blogs - Linear and Nonlinear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine Learning Blogs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Md-Shahedul-Haque/MachineLearningBlogs" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/md-shahedul-haque-shawon-5023491b7/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Linear and Nonlinear Regression</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Linear Regression</div>
                <div class="quarto-category">Nonlinear Regression</div>
                <div class="quarto-category">Code</div>
                <div class="quarto-category">Visualization</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Md Shahedul Haque </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 29, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    <div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD"><i class="bi bi-journal-code"></i>Linear and Nonlinear Regression with scikit-learn Library</a></li></ul></div></div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="sec-listTypes" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-listTypes"><span class="header-section-number">1</span> Regression in Machine Learning</h2>
<p>Supervised machine learning is a type of machine learning where the algorithm learns from labelled data. Labeled data means the dataset whose respective target value is already known. Depending on the output of models, we can divide Supervised machine learning models into two categories:</p>
<ol type="1">
<li><p><strong>Regression:</strong> It predicts the continuous output variables based on the independent input variable. Such as, the prediction of house prices based on different parameters like house age, distance from the main road, location, area, etc.</p></li>
<li><p><strong>Classification:</strong> It predicts the class/category of a datapoint based on the independent input variable. Here, outcome is a categorical or discrete value. For example, given image of an animal is a cat or dog.</p></li>
</ol>
<p>Regression computes the relationship between the dependent variables or criterion variables and one or more independent variables or predictors. &nbsp;</p>
<p>Several types of regression techniques are available. Each of them are suited for different types of data and different types of relationships. The main types of regression techniques are:</p>
<ol type="1">
<li><p>Linear Regression</p></li>
<li><p>Polynomial Regression</p></li>
<li><p>Stepwise Regression</p></li>
<li><p>Decision Tree Regression</p></li>
<li><p>Random Forest Regression</p></li>
<li><p>Support Vector Regression</p></li>
<li><p>Ridge Regression</p></li>
<li><p>Lasso Regression</p></li>
<li><p>ElasticNet Regression</p></li>
<li><p>Bayesian Linear Regression</p></li>
</ol>
</section>
<section id="linear-regression" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="linear-regression"><span class="header-section-number">2</span> Linear Regression</h2>
<p>Linear regression is used for predictive analysis. It is a linear approach for modeling the relationship between the criterion or the scalar response and the multiple predictors or explanatory variables. Linear regression focuses on the conditional probability distribution of the response given the values of the predictors.</p>
<section id="formula-for-linear-regression-model" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="formula-for-linear-regression-model"><span class="header-section-number">2.1</span> Formula for Linear Regression Model</h3>
<p>The simplest form of linear regression involved only one independent variable and one dependent variable. The equation for simple linear regression is:</p>
<p><span class="math display">\[
y=\theta x+b
\]</span></p>
<p>where,</p>
<ul>
<li><p><span class="math inline">\(y\)</span> is the dependent variable</p></li>
<li><p><span class="math inline">\(x\)</span> is the independent variable</p></li>
<li><p><span class="math inline">\(\theta\)</span> is the model weights or parameters</p></li>
<li><p><span class="math inline">\(b\)</span> is the bias</p></li>
</ul>
<p>Multiple Linear Regression involves more than one independent variable and one dependent variable. The equation for multiple linear regression is:</p>
<p><span class="math display">\[
y=b+\theta_1 x_1+\theta_2 x_2+\theta_3 x_3+...+\theta_n x_n
\]</span></p>
<p>where,</p>
<ul>
<li><p><span class="math inline">\(y\)</span> is the dependent variable</p></li>
<li><p><span class="math inline">\(x_1, x_2, x_3, ..., x_n\)</span> are the independent variables</p></li>
<li><p><span class="math inline">\(\theta_1, \theta_2, ..., \theta_n\)</span> are the model weights or parameters</p></li>
<li><p><span class="math inline">\(b\)</span> is the bias</p></li>
</ul>
</section>
<section id="assumption-for-linear-regression-model" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="assumption-for-linear-regression-model"><span class="header-section-number">2.2</span> Assumption for Linear Regression Model</h3>
<p>A linear regression model needs to meet a few conditions in order to be accurate and dependable solutions:</p>
<ul>
<li><p><strong>Linearity:</strong> Linear relation between independent and dependent variable</p></li>
<li><p><strong>Independence:</strong> Observations in the dataset are independent of each other.</p></li>
<li><p><strong>Homoscedasticity:</strong> Amount of the independent variable(s) has no impact on the variance of the errors</p></li>
<li><p><strong>Normality:</strong> The residuals should be normally distributed</p></li>
<li><p><strong>No Multicollinearity:</strong> No high correlation between the independent variables.</p></li>
</ul>
</section>
<section id="california-housing-dataset" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="california-housing-dataset"><span class="header-section-number">2.3</span> California Housing dataset</h3>
<p>We will be using <a href="https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html">California Housing dataset</a> for visualizing regression models. This dataset was derived from the 1990 U.S. census, using one row per census block group. Code snippet for loading this dataset and checking its description:</p>
<div class="quarto-embed-nb-cell">
<div id="load_dataset" class="cell" data-outputid="4a442180-dcff-49ed-bb29-f1e2ae814cd7" data-execution_count="48">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pylab <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the California Housing dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>california_housing <span class="op">=</span> datasets.fetch_california_housing(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(california_housing.DESCR)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the California Housing dataset as a DataFrame</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>df_california_housing <span class="op">=</span> california_housing.frame</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first few entries of the DataFrame</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_california_housing.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>.. _california_housing_dataset:

California Housing dataset
--------------------------

**Data Set Characteristics:**

    :Number of Instances: 20640

    :Number of Attributes: 8 numeric, predictive attributes and the target

    :Attribute Information:
        - MedInc        median income in block group
        - HouseAge      median house age in block group
        - AveRooms      average number of rooms per household
        - AveBedrms     average number of bedrooms per household
        - Population    block group population
        - AveOccup      average number of household members
        - Latitude      block group latitude
        - Longitude     block group longitude

    :Missing Attribute Values: None

This dataset was obtained from the StatLib repository.
https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html

The target variable is the median house value for California districts,
expressed in hundreds of thousands of dollars ($100,000).

This dataset was derived from the 1990 U.S. census, using one row per census
block group. A block group is the smallest geographical unit for which the U.S.
Census Bureau publishes sample data (a block group typically has a population
of 600 to 3,000 people).

A household is a group of people residing within a home. Since the average
number of rooms and bedrooms in this dataset are provided per household, these
columns may take surprisingly large values for block groups with few households
and many empty houses, such as vacation resorts.

It can be downloaded/loaded using the
:func:`sklearn.datasets.fetch_california_housing` function.

.. topic:: References

    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,
      Statistics and Probability Letters, 33 (1997) 291-297

   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \
0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   
1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   
2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   
3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   
4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   

   Longitude  MedHouseVal  
0    -122.23        4.526  
1    -122.22        3.585  
2    -122.24        3.521  
3    -122.25        3.413  
4    -122.25        3.422  </code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#load_dataset">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Next, we choose some features as independent features such as, median income in block group, median house age, average number of rooms and bedrooms per household, average number of household members and block group population. In this case, our target (dependent) variable is median value of the house (in units of <span class="math inline">\(100,000\)</span>). Also we split the <span class="math inline">\(20640\)</span> records for train and test following <span class="math inline">\(80-20\)</span> ratio:</p>
<div class="quarto-embed-nb-cell">
<div id="feature" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the specified features</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>features_of_interest <span class="op">=</span> [<span class="st">"MedInc"</span>, <span class="st">"HouseAge"</span>, <span class="st">"AveRooms"</span>, <span class="st">"AveBedrms"</span>, <span class="st">"AveOccup"</span>, <span class="st">"Population"</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Acquiring independent and dependent variables</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_california_housing[features_of_interest]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_california_housing[<span class="st">'MedHouseVal'</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-2" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#feature">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
</section>
<section id="visualization-for-linear-regression-model" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="visualization-for-linear-regression-model"><span class="header-section-number">2.4</span> Visualization for Linear Regression Model</h3>
<p>For a simple linear regression model, we utilize the scikit-learn machine library through these three. generic steps:</p>
<ol type="1">
<li><p>Creating the desired model</p></li>
<li><p>Train the model on processed training set</p></li>
<li><p>Making predictions on the test set and evaluating it</p></li>
</ol>
<p>Code snippet for a linear regression model:</p>
<div class="quarto-embed-nb-cell">
<div id="linreg_model" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a linear regression model</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model on the training set</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-3" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#linreg_model">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>We create a generic function which takes prediction label and actual label for evaluating the performance of our model. Code snippet for this function:</p>
<div class="quarto-embed-nb-cell">
<div id="performance" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> performance_stat(y_test, y_pred):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, mean_squared_error, r2_score</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate regression metrics</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Mean Absolute Error (MAE): </span><span class="sc">{</span>mae<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Mean Squared Error (MSE): </span><span class="sc">{</span>mse<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'Root Mean Squared Error (RMSE): </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f'R-squared (R²): </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-4" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#performance">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Later, we utilize this function to evaluate the performance of our linear regression model:</p>
<div class="quarto-embed-nb-cell">
<div id="linreg_performance" class="cell" data-outputid="eccb94ae-a0eb-42d3-f27b-ef55a707f97c" data-execution_count="52">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>performance_stat(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Absolute Error (MAE): 0.58
Mean Squared Error (MSE): 0.64
Root Mean Squared Error (RMSE): 0.80
R-squared (R²): 0.51</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-5" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#linreg_performance">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>An <span class="math inline">\(R^2\)</span> of <span class="math inline">\(0.51\)</span> means that the model explains about <span class="math inline">\(51\%\)</span> of the variance in the target variable. Since various factors influence house prices, an <span class="math inline">\(R^2\)</span> of <span class="math inline">\(0.51\)</span> indicates a moderate level of explanatory power. The model captures a significant portion of the variability in the target variable.</p>
<p>Next, we plot predictions by this model with respect to the actual data:</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-outputid="9b4da8c9-944c-4af4-bfcb-fd43891f64c5" data-execution_count="53">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))  <span class="co"># Set a square figure size</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot y_pred in red</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot y_test as a line for reference</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plt.plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Actual'</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Median House Value'</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Median House Value'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Linear Regression on California Housing Dataset'</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.legend()  <span class="co"># Show legend to distinguish between actual and predicted</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-linreg" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-linreg-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Linear Regression on the California Housing dataset</figcaption>
</figure>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-6" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Since the red dots (predicted data) is close to the green (actual data) line, this model can predict the target variable well.</p>
</section>
</section>
<section id="nonlinear-regression" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="nonlinear-regression"><span class="header-section-number">3</span> Nonlinear Regression</h2>
<p>Nonlinear regression is a statistical technique which assists in describing the non linearity in relationship between independent and dependent variables. Nonlinear regression models are described with a nonlinear equation. Typically, nonlinear regression is well suited to explain relations between variables in real life data. There are a lot of nonlinear regression models, refer to the previously mentioned list of regression techniques in section <a href="#sec-listTypes">Section&nbsp;1</a> if needed. In the scope of this blog, we confine our discussions to two types of nonlinear regression.</p>
<section id="support-vector-regressor-svr" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="support-vector-regressor-svr"><span class="header-section-number">3.1</span> Support Vector Regressor (SVR)</h3>
<p>Support vector regression (SVR) is a type of support vector machine (SVM) that is used for regression tasks. It attempts to find a function that best predicts the continuous output value of target for given input values of independent variables. SVR can have both linear and non-linear kernels. We will be using a radial basis function (RBF) kernel which is a non linear one.</p>
<p>Code snippet for scaling the values of feature so that features with higher values can not dominate the lower value ones. Feature scaling is a must for SVR to speed up convergence and improve model performance. Also we scale the target values accordingly:</p>
<div class="quarto-embed-nb-cell">
<div id="svr_scale" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize the features</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>scaler_X <span class="op">=</span> StandardScaler()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler_X.fit_transform(X_train)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler_X.transform(X_test)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize the target variable</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>scaler_y <span class="op">=</span> StandardScaler()</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape the target variable to a 1D array</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>y_train_scaled <span class="op">=</span> scaler_y.fit_transform(y_train.values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).ravel()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-7" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#svr_scale">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Similar to our prior example, we create the regression model at first:</p>
<div class="quarto-embed-nb-cell">
<div id="svr_model" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an SVR model on RBF kernel</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'rbf'</span>, C<span class="op">=</span><span class="dv">100</span>, gamma<span class="op">=</span><span class="fl">0.1</span>, epsilon<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>model.fit(X_train_scaled, y_train_scaled.ravel())</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>y_pred_scaled <span class="op">=</span> model.predict(X_test_scaled)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Inverse transform the predictions to the original scale</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> scaler_y.inverse_transform(y_pred_scaled.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).ravel()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-8" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#svr_model">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Then, we utilize the predefined function to evaluate the performance of this nonlinear regression model:</p>
<div class="quarto-embed-nb-cell">
<div id="svr_performance" class="cell" data-outputid="9251a349-2c8f-449b-aa6d-c1fd8d441c5a" data-execution_count="56">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>performance_stat(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Absolute Error (MAE): 0.46
Mean Squared Error (MSE): 0.45
Root Mean Squared Error (RMSE): 0.67
R-squared (R²): 0.66</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-9" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#svr_performance">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Here, we can see <span class="math inline">\(R^2\)</span> of <span class="math inline">\(0.66\)</span> which means that the model explains about <span class="math inline">\(66\%\)</span> of the variance in the target variable. So this model performs better than the previous model.</p>
<p>Next, we plot predictions by this model with respect to the actual data:</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-outputid="f1e42fc2-f432-406d-b571-42c4f1af65ee" data-execution_count="57">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))  <span class="co"># Set a square figure size</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot y_pred in red</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot y_test as a line for reference</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Actual'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Median House Value'</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Median House Value'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'SVR (RBF Kernel) on California Housing Dataset'</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-svr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-svr-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Noninear Regression (SVR with RBF Kernel) on the California Housing dataset</figcaption>
</figure>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-10" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Since the red dots (predicted data) is closer to the green (actual data) line, this model can predict the target variable well.</p>
</section>
<section id="random-forest-regressor" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="random-forest-regressor"><span class="header-section-number">3.2</span> Random Forest Regressor</h3>
<p>Random Forest Regression is a versatile technique for predicting numerical values. To reduce overfitting and improve overall accuracy, It combines the predictions of multiple decision trees.</p>
<p>Similar to our previous example, we create the regression model at first:</p>
<div class="quarto-embed-nb-cell">
<div id="rfr_model" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Random Forest Regressor</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-11" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#rfr_model">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Then, we use the predefined performance function to evaluate the this nonlinear regression model:</p>
<div class="quarto-embed-nb-cell">
<div id="rfr_performance" class="cell" data-outputid="15285565-1667-4d05-cb66-433301026b1f" data-execution_count="59">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>performance_stat(y_test, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Absolute Error (MAE): 0.46
Mean Squared Error (MSE): 0.42
Root Mean Squared Error (RMSE): 0.65
R-squared (R²): 0.68</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-12" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD#rfr_performance">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Here, we can see <span class="math inline">\(R^2\)</span> of <span class="math inline">\(0.68\)</span> which means that the model explains about <span class="math inline">\(0.68\%\)</span> of the variance in the target variable. So this model performs better than the previous models.</p>
<p>Next, we plot predictions by this model with respect to the actual data:</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-outputid="9d28539a-1be1-400f-c489-272ba4483fa3" data-execution_count="60">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))  <span class="co"># Set a square figure size</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot y_pred in red</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(y_test, y_pred, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Predicted'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot y_test as a line for reference</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Actual'</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Median House Value'</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Median House Value'</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Random Forest Regressor on California Housing Dataset'</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-rfr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-rfr-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Noninear Regression (Random Forest Regressor) on the California Housing dataset</figcaption>
</figure>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-13" href="https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD">Source: Linear and Nonlinear Regression with scikit-learn Library</a></div>
<p>Since the red dots (predicted data) is closer to the green (actual data) line, this model can predict the target variable very well.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Linear and Nonlinear Regression"</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Md Shahedul Haque"</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-29"</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Linear Regression, Nonlinear Regression, Code, Visualization]</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "regression.png"</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="an">notebook-view:</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - notebook: _regression_visual.ipynb</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">    title: "Linear and Nonlinear Regression with scikit-learn Library"</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://colab.research.google.com/drive/196SAQVmUmIH0K-6PqxwuliTGEdAjcexd#scrollTo=2CxyvQ57BVTD</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression in Machine Learning  {#sec-listTypes}</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>Supervised machine learning is a type of machine learning where the algorithm learns from labelled data. Labeled data means the dataset whose respective target value is already known. Depending on the output of models, we can divide Supervised machine learning models into two categories:</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Regression:** It predicts the continuous output variables based on the independent input variable. Such as, the prediction of house prices based on different parameters like house age, distance from the main road, location, area, etc.</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Classification:** It predicts the class/category of a datapoint based on the independent input variable. Here, outcome is a categorical or discrete value. For example, given image of an animal is a cat or dog.</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>Regression computes the relationship between the dependent variables or criterion variables and one or more independent variables or predictors. &nbsp;</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>Several types of regression techniques are available. Each of them are suited for different types of data and different types of relationships. The main types of regression techniques are:</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Linear Regression</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Polynomial Regression</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Stepwise Regression</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Decision Tree Regression</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Random Forest Regression</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>Support Vector Regression</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Ridge Regression</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="ss">8.  </span>Lasso Regression</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="ss">9.  </span>ElasticNet Regression</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="ss">10. </span>Bayesian Linear Regression</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linear Regression</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>Linear regression is used for predictive analysis. It is a linear approach for modeling the relationship between the criterion or the scalar response and the multiple predictors or explanatory variables. Linear regression focuses on the conditional probability distribution of the response given the values of the predictors.</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="fu">### Formula for Linear Regression Model</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>The simplest form of linear regression involved only one independent variable and one dependent variable. The equation for simple linear regression is:</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>y=\theta x+b</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>where,</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$y$ is the dependent variable</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x$ is the independent variable</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\theta$ is the model weights or parameters</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$b$ is the bias</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>Multiple Linear Regression involves more than one independent variable and one dependent variable. The equation for multiple linear regression is:</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>y=b+\theta_1 x_1+\theta_2 x_2+\theta_3 x_3+...+\theta_n x_n</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>where,</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$y$ is the dependent variable</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x_1, x_2, x_3, ..., x_n$ are the independent variables</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\theta_1, \theta_2, ..., \theta_n$ are the model weights or parameters</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$b$ is the bias</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assumption for Linear Regression Model</span></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>A linear regression model needs to meet a few conditions in order to be accurate and dependable solutions:</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Linearity:** Linear relation between independent and dependent variable</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Independence:** Observations in the dataset are independent of each other.</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Homoscedasticity:** Amount of the independent variable(s) has no impact on the variance of the errors</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Normality:** The residuals should be normally distributed</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**No Multicollinearity:** No high correlation between the independent variables.</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a><span class="fu">### California Housing dataset</span></span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>We will be using <span class="co">[</span><span class="ot">California Housing dataset</span><span class="co">](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)</span> for visualizing regression models. This dataset was derived from the 1990 U.S. census, using one row per census block group. Code snippet for loading this dataset and checking its description:</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#load_dataset echo=true &gt;}}</span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>Next, we choose some features as independent features such as, median income in block group, median house age, average number of rooms and bedrooms per household, average number of household members and block group population. In this case, our target (dependent) variable is median value of the house (in units of $100,000$). Also we split the $20640$ records for train and test following $80-20$ ratio:</span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#feature echo=true &gt;}}</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visualization for Linear Regression Model</span></span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>For a simple linear regression model, we utilize the scikit-learn machine library through these three. generic steps:</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Creating the desired model</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Train the model on processed training set</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Making predictions on the test set and evaluating it</span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>Code snippet for a linear regression model:</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#linReg_model echo=true &gt;}}</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>We create a generic function which takes prediction label and actual label for evaluating the performance of our model. Code snippet for this function:</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#performance echo=true &gt;}}</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>Later, we utilize this function to evaluate the performance of our linear regression model:</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#linReg_performance echo=true &gt;}}</span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>An $R^2$ of $0.51$ means that the model explains about $51\%$ of the variance in the target variable. Since various factors influence house prices, an $R^2$ of $0.51$ indicates a moderate level of explanatory power. The model captures a significant portion of the variability in the target variable.</span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a>Next, we plot predictions by this model with respect to the actual data:</span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#fig-linReg echo=true &gt;}}</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>Since the red dots (predicted data) is close to the green (actual data) line, this model can predict the target variable well.</span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a><span class="fu">## Nonlinear Regression</span></span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>Nonlinear regression is a statistical technique which assists in describing the non linearity in relationship between independent and dependent variables. Nonlinear regression models are described with a nonlinear equation. Typically, nonlinear regression is well suited to explain relations between variables in real life data. There are a lot of nonlinear regression models, refer to the previously mentioned list of regression techniques in section @sec-listTypes if needed. In the scope of this blog, we confine our discussions to two types of nonlinear regression.</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a><span class="fu">### Support Vector Regressor (SVR) </span></span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>Support vector regression (SVR) is a type of support vector machine (SVM) that is used for regression tasks. It attempts to find a function that best predicts the continuous output value of target for given input values of independent variables. SVR can have both linear and non-linear kernels. We will be using a radial basis function (RBF) kernel which is a non linear one.</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>Code snippet for scaling the values of feature so that features with higher values can not dominate the lower value ones. Feature scaling is a must for SVR to speed up convergence and improve model performance. Also we scale the target values accordingly:</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#svr_scale echo=true &gt;}}</span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>Similar to our prior example, we create the regression model at first:</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#svr_model echo=true &gt;}}</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>Then, we utilize the predefined function to evaluate the performance of this nonlinear regression model:</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#svr_performance echo=true &gt;}}</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>Here, we can see $R^2$ of $0.66$ which means that the model explains about $66\%$ of the variance in the target variable. So this model performs better than the previous model.</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>Next, we plot predictions by this model with respect to the actual data:</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#fig-svr echo=true &gt;}}</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>Since the red dots (predicted data) is closer to the green (actual data) line, this model can predict the target variable well.</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Forest Regressor</span></span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a>Random Forest Regression is a versatile technique for predicting numerical values. To reduce overfitting and improve overall accuracy, It combines the predictions of multiple decision trees.</span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>Similar to our previous example, we create the regression model at first:</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#rfr_model echo=true &gt;}}</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a>Then, we use the predefined performance function to evaluate the this nonlinear regression model:</span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#rfr_performance echo=true &gt;}}</span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a>Here, we can see $R^2$ of $0.68$ which means that the model explains about $0.68\%$ of the variance in the target variable. So this model performs better than the previous models.</span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a>Next, we plot predictions by this model with respect to the actual data:</span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a>{{&lt; embed _regression_visual.ipynb#fig-rfr echo=true &gt;}}</span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a>Since the red dots (predicted data) is closer to the green (actual data) line, this model can predict the target variable very well.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Md-Shahedul-Haque/MachineLearningBlogs/blob/main/posts/regression/index.qmd" class="toc-action">View source</a></p></div></div></div></div></footer></body></html>